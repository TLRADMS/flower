{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/tyler/Desktop/flowers'\n",
    "class_names = []\n",
    "for file in os.listdir(data_dir):\n",
    "    file = file.split('_')[0].lower()\n",
    "    if file not in class_names:\n",
    "        class_names.append(file)\n",
    "# class_names = list(set(class_names))\n",
    "\n",
    "image_count = len([name for name in os.listdir(data_dir)])\n",
    "\n",
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 175\n",
    "img_width = 175\n",
    "nb_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23676 images belonging to 14 classes.\n",
      "Found 5911 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/Users/tyler/Documents/GitHub/sf20_ds17/students_submissions/ty-adams/Project 5'\n",
    "file_name = 'saved_model.pb'\n",
    "new_model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_batch, label_batch = [], []\n",
    "# for i in range(8248+1):\n",
    "#     image, label = next(validation_generator)\n",
    "#     image_batch.append(image)\n",
    "#     label_batch.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, acc = new_model.evaluate(image_batch,  label_batch, verbose=2)\n",
    "# print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "# print(new_model.predict(image_batch).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, int(true_label[i]), img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, int(true_label[i])\n",
    "    plt.grid(False)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(45), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a914cb1baa2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# class_num = int(label_batch[i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplot_value_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlabel_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "# class_num = int(label_batch[i])\n",
    "plot_image(i, result[i], label_batch, image_batch)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, result[i],  label_batch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45]\n",
    "y_pred=new_model.predict_classes(image_batch)\n",
    "con_mat = tf.math.confusion_matrix(labels=label_batch, predictions=y_pred).numpy()\n",
    "# Normalization Confusion Matrix to the interpretation of which class is being misclassified.\n",
    "\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = classes, \n",
    "                     columns = classes)\n",
    "con_mat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
